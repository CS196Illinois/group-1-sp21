{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of breeds:  120\n",
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Epoch 1/20\n",
      "26/26 [==============================] - ETA: 0s - loss: 4.8075 - acc: 0.0445\n",
      "Epoch 00001: val_loss improved from inf to 4.53964, saving model to model.h5\n",
      "26/26 [==============================] - 168s 6s/step - loss: 4.8075 - acc: 0.0445 - val_loss: 4.5396 - val_acc: 0.0500\n",
      "Epoch 2/20\n",
      "26/26 [==============================] - ETA: 0s - loss: 3.3470 - acc: 0.4820\n",
      "Epoch 00002: val_loss improved from 4.53964 to 4.19518, saving model to model.h5\n",
      "26/26 [==============================] - 169s 7s/step - loss: 3.3470 - acc: 0.4820 - val_loss: 4.1952 - val_acc: 0.1300\n",
      "Epoch 3/20\n",
      "26/26 [==============================] - ETA: 0s - loss: 2.0943 - acc: 0.8257\n",
      "Epoch 00003: val_loss improved from 4.19518 to 3.75214, saving model to model.h5\n",
      "26/26 [==============================] - 187s 7s/step - loss: 2.0943 - acc: 0.8257 - val_loss: 3.7521 - val_acc: 0.2000\n",
      "Epoch 4/20\n",
      "26/26 [==============================] - ETA: 0s - loss: 1.0566 - acc: 0.9627\n",
      "Epoch 00004: val_loss improved from 3.75214 to 3.42865, saving model to model.h5\n",
      "26/26 [==============================] - 156s 6s/step - loss: 1.0566 - acc: 0.9627 - val_loss: 3.4286 - val_acc: 0.2300\n",
      "Epoch 5/20\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.4578 - acc: 0.9952\n",
      "Epoch 00005: val_loss improved from 3.42865 to 3.19192, saving model to model.h5\n",
      "26/26 [==============================] - 182s 7s/step - loss: 0.4578 - acc: 0.9952 - val_loss: 3.1919 - val_acc: 0.2700\n",
      "Epoch 6/20\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.2055 - acc: 1.0000\n",
      "Epoch 00006: val_loss improved from 3.19192 to 3.06832, saving model to model.h5\n",
      "26/26 [==============================] - 181s 7s/step - loss: 0.2055 - acc: 1.0000 - val_loss: 3.0683 - val_acc: 0.2700\n",
      "Epoch 7/20\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.1143 - acc: 1.0000\n",
      "Epoch 00007: val_loss improved from 3.06832 to 3.02244, saving model to model.h5\n",
      "26/26 [==============================] - 165s 6s/step - loss: 0.1143 - acc: 1.0000 - val_loss: 3.0224 - val_acc: 0.2700\n",
      "Epoch 8/20\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0778 - acc: 1.0000\n",
      "Epoch 00008: val_loss improved from 3.02244 to 2.97012, saving model to model.h5\n",
      "26/26 [==============================] - 191s 7s/step - loss: 0.0778 - acc: 1.0000 - val_loss: 2.9701 - val_acc: 0.2800\n",
      "Epoch 9/20\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0565 - acc: 1.0000\n",
      "Epoch 00009: val_loss improved from 2.97012 to 2.92942, saving model to model.h5\n",
      "26/26 [==============================] - 188s 7s/step - loss: 0.0565 - acc: 1.0000 - val_loss: 2.9294 - val_acc: 0.2850\n",
      "Epoch 10/20\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0424 - acc: 1.0000\n",
      "Epoch 00010: val_loss improved from 2.92942 to 2.89139, saving model to model.h5\n",
      "26/26 [==============================] - 178s 7s/step - loss: 0.0424 - acc: 1.0000 - val_loss: 2.8914 - val_acc: 0.2700\n",
      "Epoch 11/20\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0359 - acc: 1.0000\n",
      "Epoch 00011: val_loss improved from 2.89139 to 2.86567, saving model to model.h5\n",
      "26/26 [==============================] - 178s 7s/step - loss: 0.0359 - acc: 1.0000 - val_loss: 2.8657 - val_acc: 0.2800\n",
      "Epoch 12/20\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0281 - acc: 1.0000\n",
      "Epoch 00012: val_loss improved from 2.86567 to 2.85368, saving model to model.h5\n",
      "26/26 [==============================] - 164s 6s/step - loss: 0.0281 - acc: 1.0000 - val_loss: 2.8537 - val_acc: 0.2850\n",
      "Epoch 13/20\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0246 - acc: 1.0000\n",
      "Epoch 00013: val_loss improved from 2.85368 to 2.83669, saving model to model.h5\n",
      "26/26 [==============================] - 165s 6s/step - loss: 0.0246 - acc: 1.0000 - val_loss: 2.8367 - val_acc: 0.2900\n",
      "Epoch 14/20\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0216 - acc: 1.0000\n",
      "Epoch 00014: val_loss improved from 2.83669 to 2.81726, saving model to model.h5\n",
      "26/26 [==============================] - 155s 6s/step - loss: 0.0216 - acc: 1.0000 - val_loss: 2.8173 - val_acc: 0.2850\n",
      "Epoch 15/20\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0184 - acc: 1.0000\n",
      "Epoch 00015: val_loss improved from 2.81726 to 2.80196, saving model to model.h5\n",
      "26/26 [==============================] - 177s 7s/step - loss: 0.0184 - acc: 1.0000 - val_loss: 2.8020 - val_acc: 0.2900\n",
      "Epoch 16/20\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0166 - acc: 1.0000\n",
      "Epoch 00016: val_loss improved from 2.80196 to 2.78505, saving model to model.h5\n",
      "26/26 [==============================] - 177s 7s/step - loss: 0.0166 - acc: 1.0000 - val_loss: 2.7850 - val_acc: 0.2850\n",
      "Epoch 17/20\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0149 - acc: 1.0000\n",
      "Epoch 00017: val_loss improved from 2.78505 to 2.77135, saving model to model.h5\n",
      "26/26 [==============================] - 164s 6s/step - loss: 0.0149 - acc: 1.0000 - val_loss: 2.7714 - val_acc: 0.2850\n",
      "Epoch 18/20\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0129 - acc: 1.0000\n",
      "Epoch 00018: val_loss improved from 2.77135 to 2.75815, saving model to model.h5\n",
      "26/26 [==============================] - 156s 6s/step - loss: 0.0129 - acc: 1.0000 - val_loss: 2.7582 - val_acc: 0.2800\n",
      "Epoch 19/20\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0120 - acc: 1.0000\n",
      "Epoch 00019: val_loss improved from 2.75815 to 2.74690, saving model to model.h5\n",
      "26/26 [==============================] - 165s 6s/step - loss: 0.0120 - acc: 1.0000 - val_loss: 2.7469 - val_acc: 0.2800\n",
      "Epoch 20/20\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.0111 - acc: 1.0000\n",
      "Epoch 00020: val_loss improved from 2.74690 to 2.73784, saving model to model.h5\n",
      "26/26 [==============================] - 179s 7s/step - loss: 0.0111 - acc: 1.0000 - val_loss: 2.7378 - val_acc: 0.2750\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from glob import glob\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras_adabound import AdaBound\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def build_model(size, num_classes):\n",
    "    inputs = Input((size, size, 3))\n",
    "    backbone = MobileNetV2(input_tensor = inputs, include_top=False, weights = \"imagenet\")\n",
    "    backbone.trainable = True\n",
    "    x = backbone.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(1024, activation=\"relu\")(x)\n",
    "    x = Dense(num_classes, activation=\"softmax\")(x)\n",
    "    \n",
    "    model = tf.keras.Model(inputs, x)\n",
    "    return model\n",
    "\n",
    "def read_image(path, size):\n",
    "    image = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    image = cv2.resize(image, (size, size))\n",
    "    image = image / 255.0\n",
    "    image = image.astype(np.float32)\n",
    "    return image\n",
    "\n",
    "def parse_data(x, y):\n",
    "    x = x.decode()\n",
    "    \n",
    "    num_class = 120\n",
    "    size = 224\n",
    "    \n",
    "    image = read_image(x, size)\n",
    "    label = [0] * num_class\n",
    "    label[y] = 1\n",
    "    label = np.array(label)\n",
    "    label = label.astype(np.int32)\n",
    "    \n",
    "    return image, label\n",
    "\n",
    "def tf_parse(x, y):\n",
    "    x, y = tf.numpy_function(parse_data, [x, y], [tf.float32, tf.int32])\n",
    "    x.set_shape((224, 224, 3))\n",
    "    y.set_shape((120))\n",
    "    return x, y\n",
    "\n",
    "def tf_dataset(x, y, batch=8):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "    dataset = dataset.map(tf_parse)\n",
    "    dataset = dataset.batch(batch)\n",
    "    dataset = dataset.repeat()\n",
    "    return dataset\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    path = \"dog-breed-identification/\"\n",
    "    train_path = os.path.join(path, \"train/*\")\n",
    "    test_path = os.path.join(path, \"test/*\")\n",
    "    labels_path = os.path.join(path, \"labels.csv\")\n",
    "    \n",
    "    labels_df = pd.read_csv(labels_path)\n",
    "    breed = labels_df[\"breed\"].unique()\n",
    "    print(\"Number of breeds: \", len(breed))\n",
    "          \n",
    "    breed2id = {name: i for i, name in enumerate(breed)}\n",
    "        \n",
    "    ids = glob(train_path)\n",
    "    labels = []\n",
    "    \n",
    "    for image_id in ids:\n",
    "        image_id = image_id.split(\"\\\\\")[-1].split(\".\")[0]\n",
    "        breed_name = list(labels_df[labels_df.id == image_id][\"breed\"])[0]\n",
    "        breed_idx = breed2id[breed_name]\n",
    "        labels.append(breed_idx)\n",
    "        \n",
    "    ids = ids[:1000]\n",
    "    labels = labels[:1000]\n",
    "        \n",
    "    ##Splitting data set\n",
    "    \n",
    "    train_x, valid_x = train_test_split(ids, test_size=0.2, random_state=42) ##test size 20%\n",
    "    train_y, valid_y = train_test_split(labels, test_size=0.2, random_state=42)\n",
    "    \n",
    "    ##parameters\n",
    "    size = 224\n",
    "    num_classes = 120\n",
    "    lr = 1e-4\n",
    "    batch = 32\n",
    "    epochs = 20\n",
    "    \n",
    "    ## Building the model\n",
    "    \n",
    "    model = build_model(size, num_classes)\n",
    "    opt = tf.keras.optimizers.Adam(lr=lr)\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"acc\"])\n",
    "    \n",
    "\n",
    "    ## Dataset\n",
    "    \n",
    "    train_dataset = tf_dataset(train_x, train_y, batch = batch)\n",
    "    valid_dataset = tf_dataset(valid_x, valid_y, batch = batch)\n",
    "    \n",
    "    ## Training\n",
    "    \n",
    "    callbacks = [\n",
    "        ModelCheckpoint(\"model.h5\", verbose=1, save_best_only=True),\n",
    "        ReduceLROnPlateau(factor = 0.2, patience = 5, min_lr = 1e-6)\n",
    "    ]\n",
    "    \n",
    "    train_steps = (len(train_x)//batch) + 1\n",
    "    valid_steps = (len(valid_x)//batch) + 1\n",
    "    model.fit(train_dataset,\n",
    "        steps_per_epoch=train_steps,\n",
    "        validation_steps=valid_steps,\n",
    "        validation_data=valid_dataset,\n",
    "        epochs=epochs,\n",
    "        callbacks=callbacks)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras-adaboundNote: you may need to restart the kernel to use updated packages.\n",
      "  Downloading keras-adabound-0.6.0.tar.gz (5.5 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\ericg\\anaconda3\\envs\\tensorflow-session\\lib\\site-packages (from keras-adabound) (1.20.1)\n",
      "Collecting Keras\n",
      "  Downloading Keras-2.4.3-py2.py3-none-any.whl (36 kB)\n",
      "Collecting typeguard\n",
      "  Downloading typeguard-2.12.0-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\users\\ericg\\anaconda3\\envs\\tensorflow-session\\lib\\site-packages (from Keras->keras-adabound) (1.6.2)\n",
      "Collecting pyyaml\n",
      "  Downloading PyYAML-5.4.1-cp38-cp38-win_amd64.whl (213 kB)\n",
      "Requirement already satisfied: h5py in c:\\users\\ericg\\anaconda3\\envs\\tensorflow-session\\lib\\site-packages (from Keras->keras-adabound) (2.10.0)\n",
      "Requirement already satisfied: six in c:\\users\\ericg\\anaconda3\\envs\\tensorflow-session\\lib\\site-packages (from h5py->Keras->keras-adabound) (1.15.0)\n",
      "Building wheels for collected packages: keras-adabound\n",
      "  Building wheel for keras-adabound (setup.py): started\n",
      "  Building wheel for keras-adabound (setup.py): finished with status 'done'\n",
      "  Created wheel for keras-adabound: filename=keras_adabound-0.6.0-py3-none-any.whl size=6608 sha256=6fe272cb390a953dbbc3ec91a219d4eb2a6521c00890202962c7418b84bafa66\n",
      "  Stored in directory: c:\\users\\ericg\\appdata\\local\\pip\\cache\\wheels\\bc\\8a\\34\\f7fd8b562417782e64c61fd17829dc5a153a46ec58065aa570\n",
      "Successfully built keras-adabound\n",
      "Installing collected packages: pyyaml, typeguard, Keras, keras-adabound\n",
      "Successfully installed Keras-2.4.3 keras-adabound-0.6.0 pyyaml-5.4.1 typeguard-2.12.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install keras-adabound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
